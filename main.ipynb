{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestRegressor\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m GradientBoostingRegressor\n\u001b[0;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mxgboost\u001b[39;00m \u001b[39mimport\u001b[39;00m XGBRegressor\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightgbm\u001b[39;00m \u001b[39mimport\u001b[39;00m LGBMRegressor\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcatboost\u001b[39;00m \u001b[39mimport\u001b[39;00m CatBoostRegressor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/get_around_pricing_project.csv', index_col=0)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4843 entries, 0 to 4842\n",
      "Data columns (total 14 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   model_key                  4843 non-null   object\n",
      " 1   mileage                    4843 non-null   int64 \n",
      " 2   engine_power               4843 non-null   int64 \n",
      " 3   fuel                       4843 non-null   object\n",
      " 4   paint_color                4843 non-null   object\n",
      " 5   car_type                   4843 non-null   object\n",
      " 6   private_parking_available  4843 non-null   bool  \n",
      " 7   has_gps                    4843 non-null   bool  \n",
      " 8   has_air_conditioning       4843 non-null   bool  \n",
      " 9   automatic_car              4843 non-null   bool  \n",
      " 10  has_getaround_connect      4843 non-null   bool  \n",
      " 11  has_speed_regulator        4843 non-null   bool  \n",
      " 12  winter_tires               4843 non-null   bool  \n",
      " 13  rental_price_per_day       4843 non-null   int64 \n",
      "dtypes: bool(7), int64(3), object(4)\n",
      "memory usage: 335.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model_key                    0.0\n",
       "mileage                      0.0\n",
       "engine_power                 0.0\n",
       "fuel                         0.0\n",
       "paint_color                  0.0\n",
       "car_type                     0.0\n",
       "private_parking_available    0.0\n",
       "has_gps                      0.0\n",
       "has_air_conditioning         0.0\n",
       "automatic_car                0.0\n",
       "has_getaround_connect        0.0\n",
       "has_speed_regulator          0.0\n",
       "winter_tires                 0.0\n",
       "rental_price_per_day         0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Percentage of missing values: \")\n",
    "display(100*df.isnull().sum()/df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features\n",
    "X = df.drop('rental_price_per_day', axis=1)\n",
    "\n",
    "# Extract the target column\n",
    "y = df.loc[:, 'rental_price_per_day']\n",
    "\n",
    "# Train / test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine categorical and numerical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "# Numerical Transformer\n",
    "numerical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical Transformer\n",
    "categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_transformer\", numerical_transformer, numerical_features),\n",
    "        (\"categorical_transformer\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# X_train = preprocessor.fit_transform(X_train)\n",
    "# X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestRegressor, GradientBoostingRegressor\n\u001b[1;32m      5\u001b[0m \u001b[39m# List of models\u001b[39;00m\n\u001b[1;32m      6\u001b[0m models \u001b[39m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     LinearRegression(),\n\u001b[0;32m----> 8\u001b[0m     Ridge(),\n\u001b[1;32m      9\u001b[0m     Lasso(),\n\u001b[1;32m     10\u001b[0m     \u001b[39m# ElasticNet(),\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[39m# SVR(),\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[39m# DecisionTreeRegressor(),\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[39m# RandomForestRegressor(),\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[39m# GradientBoostingRegressor(),\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[39m# XGBRegressor(),\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[39m# LGBMRegressor(),\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[39m# CatBoostRegressor(verbose=0)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m ]\n\u001b[1;32m     20\u001b[0m \u001b[39m# List of param_grids for each model\u001b[39;00m\n\u001b[1;32m     21\u001b[0m param_grids \u001b[39m=\u001b[39m [\n\u001b[1;32m     22\u001b[0m     {},  \u001b[39m# Linear Regression\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     {\u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.001\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m1000\u001b[39m]}, \u001b[39m# Ridge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[39m# {'model__iterations': [100, 200, 500], 'model__learning_rate': [0.01, 0.1, 0.2], 'model__depth': [3, 6, 10], 'model__l2_leaf_reg': [1, 3, 5]}, # CatBoost Regressor\u001b[39;00m\n\u001b[1;32m     33\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ridge' is not defined"
     ]
    }
   ],
   "source": [
    "# List of models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    # ElasticNet(),\n",
    "    # SVR(),\n",
    "    # DecisionTreeRegressor(),\n",
    "    # RandomForestRegressor(),\n",
    "    # GradientBoostingRegressor(),\n",
    "    # XGBRegressor(),\n",
    "    # LGBMRegressor(),\n",
    "    # CatBoostRegressor(verbose=0)\n",
    "]\n",
    "\n",
    "# List of param_grids for each model\n",
    "param_grids = [\n",
    "    {},  # Linear Regression\n",
    "    {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, # Ridge\n",
    "    {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}, # Lasso\n",
    "    # {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]}, # ElasticNet\n",
    "    # {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'C': [0.1, 1, 10, 100], 'epsilon': [0.01, 0.1, 1, 10]}, # SVR\n",
    "    # {'max_depth': [2, 5, 10, 20], 'min_samples_split': [2, 5, 10]}, # Decision Tree Regressor\n",
    "    # {'n_estimators': [100, 200, 500], 'max_depth': [2, 5, 10, 20], 'min_samples_split': [2, 5, 10]}, # Random Forest Regressor\n",
    "    # {'n_estimators': [100, 200, 500], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [2, 5, 10], 'min_samples_split': [2, 5, 10]}, # Gradient Boosting Regressor\n",
    "    # {'n_estimators': [100, 200, 500], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [2, 5, 10], 'min_child_weight': [1, 5, 10],'gamma': [0, 0.5, 1]}, # XGB Regressor\n",
    "    # {'n_estimators': [100, 200, 500], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [2, 5, 10], 'num_leaves': [31]}, # LGBM Regressor\n",
    "    # {'model__iterations': [100, 200, 500], 'model__learning_rate': [0.01, 0.1, 0.2], 'model__depth': [3, 6, 10], 'model__l2_leaf_reg': [1, 3, 5]}, # CatBoost Regressor\n",
    "]\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['Model', 'Best_Params', 'Best_Score'])\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    param_grid = param_grids[i]\n",
    "    \n",
    "    # Create a pipeline with the preprocessor and the model\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Perform grid search with the current model and its param_grid\n",
    "    grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Store the best estimator and its score\n",
    "    best_estimator = grid.best_estimator_\n",
    "    best_score = grid.best_score_\n",
    "    \n",
    "    results.append((best_estimator, best_score))\n",
    "    print(f\"Best parameters for {model.__class__.__name__}: {grid.best_params_}\")\n",
    "    \n",
    "# Print the results DataFrame\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bloc_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
